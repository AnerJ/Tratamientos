{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oB3V0pK5Dc55","executionInfo":{"status":"ok","timestamp":1747935520270,"user_tz":-120,"elapsed":23927,"user":{"displayName":"Asier Corral Bilbao","userId":"10830110742240684078"}}},"outputs":[],"source":["from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.sql.functions import explode, split, col\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import size, split, col, lit\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml import Pipeline\n","\n","# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tmRixn5ZDc57","executionInfo":{"status":"ok","timestamp":1747935738678,"user_tz":-120,"elapsed":2998,"user":{"displayName":"Asier Corral Bilbao","userId":"10830110742240684078"}}},"outputs":[],"source":["# read local csv\n","df = spark.read.option(\"header\", True).csv(\"two_towers_chapters_unique.csv\")\n","\n","# We use the information of the first question to create the features\n","characters = [\"Sam\", \"Frodo\", \"Gollum\", \"Gandalf\", \"Orcs\", \"Aragorn\"]\n","\n","# Create a column for each character\n","for c in characters:\n","    df = df.withColumn(c, size(split(col(\"text\"), rf\"\\b{c}\\b\")) - 1)\n","\n","# count words\n","df = df.withColumn(\"word_count\", size(split(col(\"text\"), r\"\\s+\")))\n","\n","# Count sentences\n","df = df.withColumn(\"sentence_count\", size(split(col(\"text\"), r\"[.!?]\")))\n","\n","# avg sentence length\n","df = df.withColumn(\"avg_sentence_length\", col(\"word_count\") / col(\"sentence_count\"))\n","\n","# Importance empty column because we are going to write oursefls if it is important or not\n","df = df.withColumn(\"importance\", lit(None).cast(\"int\"))\n","\n","# wanted columns\n","final_columns = [\"chapter_id\", \"chapter_title\"] + characters + [\"word_count\", \"sentence_count\", \"avg_sentence_length\", \"importance\"]\n","df_final = df.select(final_columns)\n","\n","# save csv\n","df_final.write.mode(\"overwrite\").option(\"header\", True).csv(\"two_towers_features_RF.csv\")"]},{"cell_type":"markdown","metadata":{"id":"LbHFFZrZDc58"},"source":["Random Forest Training"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEFsrDtPDc59","executionInfo":{"status":"ok","timestamp":1747935806471,"user_tz":-120,"elapsed":11500,"user":{"displayName":"Asier Corral Bilbao","userId":"10830110742240684078"}},"outputId":"9c778411-013e-4cb4-e98e-8863fc2f4870"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on validation: 0.50\n","+--------------------------+----------+----------+-------------+\n","|chapter_title             |importance|prediction|probability  |\n","+--------------------------+----------+----------+-------------+\n","|THE VOICE OF SARUMAN      |0         |0.0       |[1.0,0.0]    |\n","|OF HERBS AND STEWED RABBIT|1         |0.0       |[0.75,0.25]  |\n","|THE WINDOW ON THE WEST    |0         |0.0       |[0.625,0.375]|\n","+--------------------------+----------+----------+-------------+\n","\n","Accuracy on test: 0.38\n","+------------------------+----------+----------+-------------+\n","|chapter_title           |importance|prediction|probability  |\n","+------------------------+----------+----------+-------------+\n","|THE URUK-HAI            |1         |0.0       |[0.625,0.375]|\n","|HELM’S DEEP             |0         |0.0       |[0.625,0.375]|\n","|F LOTSAM AND JETSAM     |0         |0.0       |[0.625,0.375]|\n","|THE BLACK GATE IS CLOSED|0         |0.0       |[0.625,0.375]|\n","|SHELOB’S LAIR           |0         |0.0       |[0.5,0.5]    |\n","+------------------------+----------+----------+-------------+\n","\n"]}],"source":["# Charge CSV and csv has already the importance column changed to 0 or 1\n","df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"chapters_RF.csv\")\n","\n","# Predictable values\n","features = [\"Sam\", \"Frodo\", \"Gollum\", \"Gandalf\", \"Orcs\", \"Aragorn\", \"word_count\", \"sentence_count\", \"avg_sentence_length\"]\n","assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n","\n","# Classifier\n","rf = RandomForestClassifier(\n","    labelCol=\"importance\",\n","    featuresCol=\"features\",\n","    numTrees=8,\n","    maxDepth=3,\n","    minInstancesPerNode=1,\n","    subsamplingRate=0.6,\n","    featureSubsetStrategy=\"log2\"\n",")\n","\n","# Pipeline\n","pipeline = Pipeline(stages=[assembler, rf])\n","\n","# Train, validation and test split\n","train_data, val_data, test_data = df.randomSplit([0.7, 0.1, 0.2], seed=42)\n","# train\n","model = pipeline.fit(train_data)\n","\n","# Validation\n","val_predictions = model.transform(val_data)\n","evaluator = BinaryClassificationEvaluator(labelCol=\"importance\")\n","val_accuracy = evaluator.evaluate(val_predictions)\n","\n","print(f\"Accuracy on validation: {val_accuracy:.2f}\")\n","val_predictions.select(\"chapter_title\", \"importance\", \"prediction\", \"probability\").show(truncate=False)\n","\n","# Test\n","test_predictions = model.transform(test_data)\n","test_accuracy = evaluator.evaluate(test_predictions)\n","\n","print(f\"Accuracy on test: {test_accuracy:.2f}\")\n","test_predictions.select(\"chapter_title\", \"importance\", \"prediction\", \"probability\").show(truncate=False)"]}],"metadata":{"kernelspec":{"display_name":"Python (e1)","language":"python","name":"e1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}